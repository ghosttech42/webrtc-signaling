import asyncio
import json
from playwright.async_api import async_playwright
from playwright_stealth import Stealth

# --- SENÄ°N VERDÄ°ÄÄ°N LÄ°STEDEN TEMÄ°ZLENMÄ°Å PROXYLER ---
PROXY_LIST = [
    "http://185.181.208.88:3128",
    "http://176.236.227.106:8080",
    "http://185.103.202.35:8443",
    "http://149.86.140.214:8080",
    "http://194.124.36.14:8080",
    "http://164.138.207.81:8080",
    "http://149.86.139.166:8085",
    "http://213.74.163.181:8080",
    "http://188.132.221.188:8080",
    "http://176.88.191.254:8080",
    "http://212.175.88.208:8080",
    "http://139.28.48.39:8080",
    "http://185.80.21.92:8080",
    "http://103.231.75.209:3128",
    "http://212.252.39.103:8080",
    "http://176.236.46.146:80",
    "http://95.70.235.241:8080",
    "http://212.174.242.114:8080",
    "http://185.181.208.190:3128",
    "http://31.40.204.250:80",
    "socks5://185.86.5.162:8975" # Listede bir tane SOCKS5 vardÄ±
]

# --- MOCK VERÄ°LERÄ° (Garantilemek Ä°Ã§in) ---
TR_COUNTRY_INFO = {"data": {"Catalog": {"countryData": {"defaultCurrency": "TRY","paymentCurrency": "TRY","currencySymbolPlacement": "LEFT"}}}}
TR_CURRENCY_INFO = {"data": {"Catalog": {"currency": {"decimals": 2,"code": "TRY","symbol": "â‚º"}}}}

async def run_scraper(proxy_url):
    """
    Belirli bir proxy ile scraping iÅŸlemini dener.
    BaÅŸarÄ±lÄ± olursa True dÃ¶ner ve iÅŸlemi tamamlar.
    """
    async with async_playwright() as p:
        print(f"\nğŸ”Œ Proxy deneniyor: {proxy_url}")
        
        try:
            # Proxy ile tarayÄ±cÄ±yÄ± baÅŸlat
            browser = await p.chromium.launch(
                headless=True, 
                proxy={"server": proxy_url}
            )
            
            # Context oluÅŸtur (request_timeout hatasÄ± buradaydÄ±, kaldÄ±rdÄ±k)
            context = await browser.new_context(
                viewport={"width": 1920, "height": 1080},
                locale="tr-TR",
                timezone_id="Europe/Istanbul",
                user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
            )
            
            # Timeout ayarlarÄ±nÄ± SONRADAN yapÄ±yoruz (DoÄŸrusu bu)
            context.set_default_navigation_timeout(20000) # 20 saniye iÃ§inde baÄŸlanmazsa pas geÃ§
            context.set_default_timeout(20000)
            
            # Stealth modunu aktif et
            await Stealth().use_async(context.active_page if context.pages else await context.new_page())

            # --- REQUEST INTERCEPTION (Proxy Ã§alÄ±ÅŸsa bile TL'yi zorla) ---
            async def handle_routes(route, request):
                if request.method == "POST" and "graphql" in request.url:
                    try:
                        # Giden isteÄŸi yakala ve TR parametrelerini ekle
                        if request.post_data:
                            data = json.loads(request.post_data)
                            variables = data.get("variables", {})
                            if "country" in variables or "locale" in variables:
                                variables["country"] = "TR"
                                variables["countryCode"] = "TR"
                                variables["locale"] = "tr"
                                data["variables"] = variables
                                await route.continue_(post_data=json.dumps(data))
                                return
                    except:
                        pass
                
                # Mock yanÄ±tlarÄ± (Site bize Ã¼lke sorduÄŸunda)
                if "getCatalogCountryInfo" in request.url:
                    await route.fulfill(status=200, content_type="application/json", body=json.dumps(TR_COUNTRY_INFO))
                    return
                if "getCatalogCurrencyInfo" in request.url:
                    await route.fulfill(status=200, content_type="application/json", body=json.dumps(TR_CURRENCY_INFO))
                    return
                
                await route.continue_()

            await context.route("**/*", handle_routes)

            page = await context.new_page()

            # Test iÃ§in Epic Games anasayfasÄ±na git
            print("â³ Siteye baÄŸlanÄ±lÄ±yor...")
            await page.goto("https://store.epicgames.com/tr/browse?sortBy=releaseDate&sortDir=DESC&category=Game&count=40", wait_until="domcontentloaded")
            
            # Ä°Ã§eriÄŸi kontrol et
            content = await page.content()
            
            if "â‚º" in content or "TL" in content:
                print(f"âœ… BAÅARILI! Proxy Ã§alÄ±ÅŸÄ±yor ve TL fiyatlar gÃ¶rÃ¼nÃ¼yor: {proxy_url}")
            else:
                print("âš ï¸ Proxy baÄŸlandÄ± ama TL gÃ¶remedi (veya site Ä°ngilizce aÃ§Ä±ldÄ±).")
                # Yine de veri Ã§ekmeyi deneyebiliriz ama riskli.
                # Åimdilik baÅŸarÄ±sÄ±z sayÄ±p diÄŸerine geÃ§elim en temizini bulalÄ±m.
                await browser.close()
                return False

            # --- BURAYA KADAR GELDÄ°YSEK PROXY SAÄLAMDIR, VERÄ°YÄ° Ã‡EKELÄ°M ---
            
            all_games = []
            
            # Response dinleyicisi
            async def handle_response(response):
                if "graphql" in response.url and response.status == 200:
                    try:
                        json_data = await response.json()
                        elements = []
                        # Veri yolunu bul
                        if "data" in json_data and "Catalog" in json_data["data"]:
                            cat = json_data["data"]["Catalog"]
                            if "searchStore" in cat: elements = cat["searchStore"]["elements"]
                            elif "catalogOffers" in cat: elements = cat["catalogOffers"]["elements"]
                        
                        if elements:
                            for game in elements:
                                title = game.get("title", "Bilinmiyor")
                                price = game.get("price", {}).get("totalPrice", {}).get("fmtPrice", {}).get("originalPrice", "0")
                                if title not in [g['title'] for g in all_games]: # TekrarÄ± Ã¶nle
                                    print(f"   ğŸ•¹ï¸ {title} -> {price}")
                                    all_games.append({"title": title, "price": price})
                    except: pass
            
            page.on("response", handle_response)
            
            # SayfayÄ± kaydÄ±r ki oyunlar yÃ¼klensin
            print("ğŸ“œ Oyunlar yÃ¼kleniyor (Scroll)...")
            for _ in range(3):
                await page.evaluate("window.scrollBy(0, 1000)")
                await asyncio.sleep(2)
            
            # Verileri kaydet
            if all_games:
                with open("epic_proxy_games.json", "w", encoding="utf-8") as f:
                    json.dump(all_games, f, ensure_ascii=False, indent=4)
                print(f"ğŸ‰ Toplam {len(all_games)} oyun kaydedildi.")
                await browser.close()
                return True # BaÅŸarÄ±lÄ± oldu, dÃ¶ngÃ¼den Ã§Ä±k
            
            await browser.close()
            return False

        except Exception as e:
            print(f"âŒ Proxy HatasÄ± ({proxy_url}): {str(e)[:100]}...") # HatanÄ±n sadece baÅŸÄ±nÄ± gÃ¶ster
            return False

async def main():
    print(f"ğŸš€ Toplam {len(PROXY_LIST)} adet proxy denenecek...")
    
    for proxy in PROXY_LIST:
        success = await run_scraper(proxy)
        if success:
            print("\nğŸ Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±. DiÄŸer proxyleri denemeye gerek yok.")
            break
    else:
        print("\nğŸ˜” HiÃ§bir proxy ile saÄŸlÄ±klÄ± veri Ã§ekilemedi. Listeyi gÃ¼ncellemen gerekebilir.")

if __name__ == "__main__":
    asyncio.run(main())
